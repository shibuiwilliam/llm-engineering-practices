@startuml Proxy for Rate-Limited Access Pattern - Sequence Diagram

actor Client
participant "LLMProxy" as Proxy
participant "RateLimiter" as Limiter
participant "Cache" as Cache
participant "RetryPolicy" as Retry
participant "RequestQueue" as Queue
participant "LLMService" as LLM

Client -> Proxy: requestLLMResponse(prompt)
activate Proxy

Proxy -> Cache: get(prompt)
alt Cache Hit
    Cache --> Proxy: return cached response
    Proxy --> Client: return response
else Cache Miss
    Proxy -> Limiter: checkLimit(userId)
    alt Rate Limit Exceeded
        Limiter --> Proxy: limit exceeded
        Proxy -> Queue: enqueue(request)
        Queue --> Proxy: queued
        Proxy --> Client: rate limit error
    else Within Rate Limit
        Limiter --> Proxy: within limit
        Proxy -> LLM: processRequest(request)
        alt Success
            LLM --> Proxy: response
            Proxy -> Cache: put(prompt, response)
            Proxy --> Client: return response
        else Rate Limit Error (429)
            LLM --> Proxy: 429 error
            Proxy -> Retry: shouldRetry(error)
            Retry --> Proxy: true
            Proxy -> Retry: getNextRetryDelay()
            Retry --> Proxy: delay
            Proxy -> LLM: retry request
            LLM --> Proxy: response
            Proxy -> Cache: put(prompt, response)
            Proxy --> Client: return response
        end
    end
end

deactivate Proxy

@enduml 