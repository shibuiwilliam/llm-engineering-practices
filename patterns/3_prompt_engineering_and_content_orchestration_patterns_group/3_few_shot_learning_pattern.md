# Few-shot Learning Pattern

## 説明  
Few-shot Learning Pattern は、LLM に対して「少数の事例（ショット）」をプロンプト内に含めることで、特定タスクの出力品質を向上させるパターンです。  
- **ショット数**：0-shot（例示なし）、1-shot、n-shot（複数例示）を状況に応じて使い分け  
- **例示形式**：`<入力例> → <期待出力例>` をプロンプト冒頭に複数並べ、その後に本番入力を与える  
- **コンテキスト最適化**：事例の選定や順序、フォーマットをチューニングしてモデルの理解を誘導  

## 用途  
- **テキスト分類**：レビューや問い合わせ文を「肯定／否定」「カテゴリ」などに分類  
- **データ抽出**：文章から住所・日付・金額など特定情報を抜き出す  
- **フォーマット変換**：自然文を JSON や CSV、Markdown 表形式に整形  
- **文体変換／要約**：具体例を見せながら「フォーマルに」「5 行要約」など細かい指示  

## 解決する課題  
1. **プロンプト設計難度**  
   - 指示だけではモデルがタスク意図を正しく把握しづらい  
2. **再現性の欠如**  
   - 同一指示でも結果がばらつき、安定して期待結果を得にくい  
3. **学習コスト削減**  
   - ファインチューニングせずにタスク適性を高めたい  
4. **ドメイン適応**  
   - 特定分野の事例を示し、一般用途モデルを業務ドメインに即応させる  

## 対象とするシステム／プロジェクト  
- **チャットボット／FAQ システム**：類似質問例→回答例を few-shot で示し、高品質応答を得る  
- **RAG パイプライン**：検索結果のサマリーパターンを例示し、一貫した要約フォーマットを維持  
- **データパイプライン**：ログやレポートから特定フィールド抽出を few-shot で高精度化  
- **自動ドキュメント生成**：仕様→コード生成例を示し、新規コードのスタイルを統一  

## 利用するメリット  
- **出力品質向上**：具体例提示により、モデルが意図するフォーマット・トーンを正確に把握  
- **高速適応**：少量の例示で新タスクに即応し、ファインチューニング不要  
- **コスト効率**：トークン数分のコストのみで高精度を実現  
- **開発スピード**：事例を用意するだけで PoC → 本番移行が容易  

## 注意点とトレードオフ  
- **コンテキスト長制限**  
  - 例示が多すぎるとトークン制限に引っかかり、本番入力がカットされる可能性  
- **例示選定バイアス**  
  - 不適切な事例を提示すると、モデルが誤ったパターンを学習・反復する  
- **コスト増加**  
  - 例示分のトークン量が増えるため、1 リクエストあたりのコストが上昇  
- **メンテナンス負荷**  
  - タスク要件が変わるたびに事例セットを見直す必要がある  

## 導入のヒント  
1. **代表性の高い事例を厳選**  
   - タスクの典型例・エッジ例を含め、モデルが幅広く学べるよう準備  
2. **少ないショット数から試行**  
   - まずは 1-shot／2-shot で効果を確認し、必要に応じてショット数を増減  
3. **フォーマット統一**  
   - 例示の入力・出力フォーマットを厳密に揃え、定型的に並べる  
4. **ランダムサンプリングで評価**  
   - 複数の事例組み合わせをランダムにテストし、最適セットを発見  
5. **インテグレーションテスト**  
   - CI で few-shot プロンプト結果を自動検証し、本番品質を維持  
