# Streaming Output Pattern

## 説明
Streaming Output パターンは、LLM の応答を「トークン単位」で逐次受信し、ユーザインタフェース（UI）やクライアントに即座にプッシュ表示する手法です。従来の「全レスポンス受信後に表示」に比べ、ユーザへのフィードバックが高速化し、対話やリアルタイム処理の体感応答性を大幅に向上させます。  
- **サーバー側**：`stream=true` などのストリーミングオプションでモデル呼び出し  
- **クライアント側**：受信した部分トークンをバッファリングせず即描画  
- **中間キャンセル**：一定条件（時間／トークン数）でストリームを中断  

## 用途
- **チャットボット／対話型 UI**：ユーザが「文字を打っている感覚」で回答を受け取る  
- **音声読み上げ／TTS**：トークン到着と同時に音声合成を開始し、遅延を最小化  
- **リアルタイム要約**：長文読み込み中に要約結果を逐次更新表示  
- **コーディングアシスタント**：コード補完（IDE プラグイン）で部分的に生成済みコードを即時挿入  

## 解決する課題
1. **体感レイテンシの長さ**  
   - 全トークン受信完了まで待つと、数秒～数十秒の“無応答”時間が発生  
2. **ユーザ離脱／フラストレーション**  
   - 長い待機時間で「応答していない」と思われ、操作を止められる  
3. **大規模ドキュメント生成のイテレーション不足**  
   - 完全生成後の結果に不満があっても再リクエストに時間がかかる  

## 対象システム／プロジェクト
- **Web／モバイルチャットアプリ**：リアルタイム対話感を重視する顧客サポートやパーソナルアシスタント  
- **統合開発環境（IDE）プラグイン**：AI コード補完やドキュメント生成におけるインクリメンタル表示  
- **ライブプレゼンツール**：リアルタイム要約や翻訳をセッション中に随時更新  
- **音声アシスタント**：ストリーム開始と同時に TTS を開始し、話し始めの遅延を排除  

## 利用するメリット
- **即時フィードバック**：最初のトークン到着までのレイテンシがユーザの体感に直結  
- **インタラクティブ性強化**：生成途中でユーザ条件変更や中断（キャンセル）が可能  
- **部分結果の活用**：後続処理（TTS、要約プレビューなど）を並行実行できる  
- **UX 向上**：安心感と対話感を提供し、ユーザエンゲージメントが向上  

## 注意点とトレードオフ
- **実装複雑度**  
  - HTTP／WebSocket ストリーミングのエラーハンドリング、再接続ロジックが必要  
- **中間不完全データの提示**  
  - 部分トークンをそのまま表示すると意味不明／読みづらい場合がある  
- **リソース管理**  
  - 長時間ストリームを維持するとコネクション数やメモリ使用が増大  
- **キャンセル設計**  
  - ユーザ操作による中断タイミングを適切に設計しないと途中生成が無駄に  

## 導入のヒント
1. **段階的ストリーミング**  
   - 最初は「最初の N トークンを即表示 → 残りをバッファ後表示」のハイブリッドで試験  
2. **プレースホルダ UI**  
   - 部分生成中に“…生成中”インジケータやプログレスバーを併用し、無意味トークン表示を緩和  
3. **キャンセル／修正ボタン**  
   - ユーザが途中で止められる UI 制御を提供し、不要なトークン消費を防止  
4. **バックプレッシャー制御**  
   - クライアントが一度に処理できるトークン数を制限し、描画負荷を抑制  
5. **モニタリング**  
   - ストリーミングコネクションの維持時間や部分応答速度をメトリクス化し、改善サイクルを回す  
