# Semantic Caching Pattern

## 説明  
Semantic Caching Pattern は、ユーザからの類似リクエストやプロンプトに対し、「意味的に」近い過去の LLM 出力をキャッシュして再利用することで、API 呼び出し回数とコストを削減すると同時に、応答レイテンシを改善する設計手法です。  
- **ベクトル化キー**：プロンプトや入力テキストを埋め込み（Embedding）でベクトル化し、キャッシュキーとする  
- **近傍検索**：高速な近似最近傍検索（ANN）で、類似度閾値以上の過去レスポンスをヒット  
- **キャッシュ層**：ANN インデックスとレスポンスストアを組み合わせ、低レイテンシで“意味的”キャッシュを実現  
- **失敗フォールバック**：キャッシュミス時のみ LLM API を呼び出し、得られたレスポンスをキャッシュに追加  

## 用途  
- **FAQ 自動応答**：類似質問への高速回答に既存回答を再利用し、モデル呼び出しを最小化  
- **ドキュメント要約**：同一ドキュメントや類似内容への要約リクエストをキャッシュし、バッチ処理の効率化  
- **パーソナライズ推薦**：ユーザ履歴や類似ユーザ行動に基づく推論結果をキャッシュし、レコメンド性能を向上  
- **翻訳サービス**：再翻訳が発生しやすい定型文やフレーズをキャッシュし、無料プランのコスト抑制  

## 解決する課題  
1. **冗長な API 呼び出し**  
   - 異なるユーザが似たようなプロンプトを送る度に毎回 LLM 呼び出しを行う無駄  
2. **高トークン消費コスト**  
   - キャッシュを使わず全出力を再生成すると、トークン使用量と請求額が増大  
3. **レイテンシ増大**  
   - リアルタイム対話や高頻度バッチでの繰り返し呼び出しにより応答が遅延  
4. **スケール負荷**  
   - 大量リクエスト時にモデル呼び出しがスループットのボトルネック化  

## 対象とするシステム／プロジェクト  
- **チャットボット／FAQ プラットフォーム**：よくある質問に対し即時回答を返す Web サービス  
- **RAG（Retrieval-Augmented Generation）システム**：検索したコンテキスト要約結果を頻出クエリで再利用  
- **多言語翻訳 API**：同一フレーズやパラメトリック文を複数ユーザが翻訳依頼するユースケース  
- **カスタマーサポート自動化**：過去対応履歴を基に回答を再利用し、エージェント負荷とトークン費用を削減  

## 利用するメリット  
- **コスト効率化**：キャッシュヒット時は LLM 呼び出し不要でトークン消費をゼロに  
- **高速レスポンス**：メモリ／ANN 検索のみで応答を返し、UX を大幅改善  
- **スケーラビリティ**：バックエンドモデル呼び出し負荷を平準化し、水平スケールを容易に  
- **品質一貫性**：類似プロンプトに対しても過去の高品質出力を再利用し、回答品質を安定  

## 注意点とトレードオフ  
- **キャッシュ一貫性**  
  - モデル更新後も古いキャッシュを返し続けると出力品質のズレが生じる  
- **ベクトルインデックス管理**  
  - 大規模データでの ANN インデックス更新・シャーディング設計が必要  
- **類似度閾値チューニング**  
  - 閾値が高すぎるとヒット率が低下、低すぎると不適切キャッシュを返すリスク  
- **ストレージコスト**  
  - ベクトルストアとレスポンスストアの容量、及びインデックス運用コストが発生  

## 導入のヒント  
1. **プロトタイプでヒット率評価**  
   - 初期は少量データで埋め込みと閾値を試し、キャッシュヒット率と品質影響を検証  
2. **ストア分割戦略**  
   - ホットデータ用メモリキャッシュとコールドデータ用ディスクストアを組み合わせ  
3. **モデルバージョンタグ**  
   - キャッシュエントリにモデルバージョン情報を付与し、モデル更新時に旧データを一括無効化  
4. **インバリデーションポリシー**  
   - TTL や手動パージを併用し、古くなったキャッシュを適切にクリア  
5. **モニタリングとアラート**  
   - キャッシュヒット率、平均検索レイテンシ、不適切ヒット件数をダッシュボードで監視  
